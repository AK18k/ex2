{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AK18k/ex2/blob/main/ex2_028064558_027244037_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep Learning - Ex #2\n",
        "Avi Keinan 028064558\n",
        "Ofer Ballin 027244037\n",
        "\n",
        "This notebook implements LSTM and GRU with and without dropouts"
      ],
      "metadata": {
        "id": "MtUKmt-upo9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext google.colab.data_table\n",
        "import pdb"
      ],
      "metadata": {
        "id": "sNmJlmS3Dmkb",
        "outputId": "c91f8cb2-9c83-46c3-c691-c74dfb5aa1ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The google.colab.data_table extension is already loaded. To reload it, use:\n",
            "  %reload_ext google.colab.data_table\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AK18k/ex2"
      ],
      "metadata": {
        "id": "fd4aj_pCh7VP",
        "outputId": "a9c6a742-625f-457a-9bb9-2c0b1c465514",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ex2'...\n",
            "remote: Enumerating objects: 56, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 56 (delta 12), reused 38 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (56/56), 3.82 MiB | 5.31 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "DATA_PATH = '/content/ex2/data/ptb'\n",
        "PATH = '/content/ex2'\n",
        "os.chdir('/content/ex2')\n",
        "!ls"
      ],
      "metadata": {
        "id": "IRPe9rMApsmL",
        "outputId": "fcef0417-6622-4dad-cf17-32986562eb30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adabound.py\t\t\t\t      finetune.py\t model.py\n",
            "corpus.77afd5b9c5825ef44c47fcd18f4839dd.data  generate.py\t pointer.py\n",
            "data\t\t\t\t\t      getdata.sh\t README.md\n",
            "data.py\t\t\t\t\t      LICENSE\t\t splitcross.py\n",
            "embed_regularize.py\t\t\t      locked_dropout.py  utils.py\n",
            "ex2_028064558_027244037_new.ipynb\t      main.py\t\t weight_drop.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/ex2')"
      ],
      "metadata": {
        "id": "_BC5Z_88jAF6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from adabound import AdaBound\n",
        "\n",
        "import data\n",
        "import model\n",
        "\n",
        "from utils import batchify, get_batch, repackage_hidden\n",
        "\n",
        "parser = argparse.ArgumentParser(description='PyTorch PennTreeBank RNN/LSTM Language Model')\n",
        "parser.add_argument('--data', type=str, default='data/ptb/',\n",
        "                    help='location of the data corpus')\n",
        "parser.add_argument('--model', type=str, default='LSTM',\n",
        "                    help='type of recurrent net (LSTM, QRNN, GRU)')\n",
        "parser.add_argument('--emsize', type=int, default=1500,\n",
        "                    help='size of word embeddings')\n",
        "parser.add_argument('--nhid', type=int, default=200,\n",
        "                    help='number of hidden units per layer')\n",
        "parser.add_argument('--nlayers', type=int, default=3,\n",
        "                    help='number of layers')\n",
        "parser.add_argument('--lr', type=float, default=0.1,\n",
        "                    help='initial learning rate')\n",
        "# parser.add_argument('--clip', type=float, default=0.25,\n",
        "#                     help='gradient clipping')\n",
        "parser.add_argument('--epochs', type=int, default=200,\n",
        "                    help='upper epoch limit')\n",
        "parser.add_argument('--batch_size', type=int, default=20, metavar='N',\n",
        "                    help='batch size')\n",
        "parser.add_argument('--bptt', type=int, default=70,\n",
        "                    help='sequence length')\n",
        "parser.add_argument('--dropout', type=float, default=0,\n",
        "                    help='dropout applied to layers (0 = no dropout)')\n",
        "parser.add_argument('--dropouth', type=float, default=0,\n",
        "                    help='dropout for rnn layers (0 = no dropout)')\n",
        "parser.add_argument('--dropouti', type=float, default=0,\n",
        "                    help='dropout for input embedding layers (0 = no dropout)')\n",
        "parser.add_argument('--dropoute', type=float, default=0,\n",
        "                    help='dropout to remove words from embedding layer (0 = no dropout)')\n",
        "parser.add_argument('--wdrop', type=float, default=0,\n",
        "                    help='amount of weight dropout to apply to the RNN hidden to hidden matrix')\n",
        "parser.add_argument('--seed', type=int, default=1111,\n",
        "                    help='random seed')\n",
        "parser.add_argument('--nonmono', type=int, default=1111,\n",
        "                    help='random seed')\n",
        "parser.add_argument('--cuda', action='store_false',\n",
        "                    help='use CUDA')\n",
        "parser.add_argument('--log-interval', type=int, default=200, metavar='N',\n",
        "                    help='report interval')\n",
        "randomhash = ''.join(str(time.time()).split('.'))\n",
        "parser.add_argument('--save', type=str,  default=randomhash+'.pt',\n",
        "                    help='path to save the final model')\n",
        "parser.add_argument('--alpha', type=float, default=2,\n",
        "                    help='alpha L2 regularization on RNN activation (alpha = 0 means no regularization)')\n",
        "parser.add_argument('--beta', type=float, default=1,\n",
        "                    help='beta slowness regularization applied on RNN activiation (beta = 0 means no regularization)')\n",
        "parser.add_argument('--wdecay', type=float, default=5e-4,\n",
        "                    help='weight decay applied to all weights')\n",
        "parser.add_argument('--resume', type=str,  default='',\n",
        "                    help='path of model to resume')\n",
        "parser.add_argument('--when', nargs=\"+\", type=int, default=[-1],\n",
        "                    help='When (which epochs) to divide the learning rate by 10 - accepts multiple')\n",
        "parser.add_argument('--optim', default='sgd', type=str, help='optimizer',\n",
        "                    choices=['sgd', 'adagrad', 'adam', 'amsgrad', 'adabound', 'amsbound'])\n",
        "parser.add_argument('--momentum', default=0.9, type=float, help='momentum term')\n",
        "parser.add_argument('--beta1', default=0.9, type=float, help='Adam coefficients beta_1')\n",
        "parser.add_argument('--beta2', default=0.999, type=float, help='Adam coefficients beta_2')\n",
        "parser.add_argument('--final_lr', default=0.1, type=float,\n",
        "                    help='final learning rate of AdaBound')\n",
        "parser.add_argument('--gamma', default=1e-3, type=float,)\n",
        "parser.add_argument('--ita',default=1e-2, type=float)\n",
        "parser.add_argument('--weight_decay', default=5e-4, type=float,\n",
        "                    help='weight decay for optimizers')\n",
        "#args = parser.parse_args()\n",
        "args, unknown = parser.parse_known_args() #change args assignment to accomodate Jupiter execution (instead of command line)\n",
        "args.tied = True\n",
        "\n",
        "# Set the random seed manually for reproducibility.\n",
        "np.random.seed(args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "print(args.cuda)\n",
        "if torch.cuda.is_available():\n",
        "    print('cuda is available')\n",
        "    if not args.cuda:\n",
        "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
        "    else:\n",
        "        torch.cuda.manual_seed(args.seed)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DjfO_4nqY7k",
        "outputId": "38a40aeb-3f49-481a-b8e6-79bc21b1da03"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "cuda is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "###############################################################################\n",
        "# Load data\n",
        "###############################################################################\n",
        "\n",
        "def model_save(fn):\n",
        "    with open(fn, 'wb') as f:\n",
        "        torch.save([model, criterion, optimizer], f)\n",
        "\n",
        "def model_load(fn):\n",
        "    global model, criterion, optimizer\n",
        "    with open(fn, 'rb') as f:\n",
        "        model, criterion, optimizer = torch.load(f)\n",
        "\n",
        "import os\n",
        "import hashlib\n",
        "fn = 'corpus.{}.data'.format(hashlib.md5(args.data.encode()).hexdigest())\n",
        "if os.path.exists(fn):\n",
        "    print('Loading cached dataset...')\n",
        "    corpus = torch.load(fn)\n",
        "else:\n",
        "    print('Producing dataset...')\n",
        "    corpus = data.Corpus(args.data)\n",
        "    torch.save(corpus, fn)\n",
        "\n",
        "eval_batch_size = 10\n",
        "\n",
        "test_batch_size = 1\n",
        "train_data = batchify(corpus.train, args.batch_size, args)\n",
        "val_data = batchify(corpus.valid, eval_batch_size, args)\n",
        "test_data = batchify(corpus.test, test_batch_size, args)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g08GWZBlXT-B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        },
        "outputId": "73804f82-ddc8-47a1-c640-059ecccd1a6d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading cached dataset...\n",
            "--Return--\n",
            "None\n",
            "> \u001b[0;32m<ipython-input-11-f92e38e0220b>\u001b[0m(27)\u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     25 \u001b[0;31m\u001b[0meval_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     26 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 27 \u001b[0;31m\u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     28 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     29 \u001b[0;31m\u001b[0mtest_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> n\n",
            "\u001b[0;31m    [... skipped 1 hidden frame]\u001b[0m\n",
            "\n",
            "\u001b[0;31m    [... skipped 1 hidden frame]\u001b[0m\n",
            "\n",
            "\u001b[0;31m    [... skipped 1 hidden frame]\u001b[0m\n",
            "\n",
            "\u001b[0;31m    [... skipped 1 hidden frame]\u001b[0m\n",
            "\n",
            "> \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m(3464)\u001b[0;36mrun_ast_nodes\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m   3462 \u001b[0;31m                    \u001b[0mto_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'single'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   3463 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m-> 3464 \u001b[0;31m                \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   3465 \u001b[0;31m                    \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exec'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   3466 \u001b[0;31m                        \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> n\n",
            "> \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m(3465)\u001b[0;36mrun_ast_nodes\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m   3463 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   3464 \u001b[0;31m                \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m-> 3465 \u001b[0;31m                    \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exec'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   3466 \u001b[0;31m                        \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   3467 \u001b[0;31m                    \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'single'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> q\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BdbQuit",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[0;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[1;32m   3463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3464\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3465\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exec'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3466\u001b[0m                         \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3467\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'single'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBdbQuit\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjjSjsQpq5Ej",
        "outputId": "8e04e9b4-be00-46ed-e3af-8606d7625f23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   0,   93,   27,  ...,  997,  392, 4210],\n",
              "        [   1,  718,  930,  ...,   42, 5518,  467],\n",
              "        [   2,  590,   42,  ...,  507, 3034, 1496],\n",
              "        ...,\n",
              "        [ 152,  170,  392,  ...,  682, 2264, 9999],\n",
              "        [4955, 6784, 4864,  ..., 6849,   42,  119],\n",
              "        [4150,  133,   26,  ..., 6344, 3401, 1143]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "# Build the model\n",
        "###############################################################################\n",
        "\n",
        "from splitcross import SplitCrossEntropyLoss\n",
        "criterion = None\n",
        "\n",
        "ntokens = len(corpus.dictionary)\n",
        "model = model.RNNModel(args.model, ntokens, args.emsize, args.nhid, args.nlayers, args.dropout, args.dropouth, args.dropouti, args.dropoute, args.wdrop, args.tied)\n",
        "###\n",
        "if args.resume:\n",
        "    print('Resuming model ...')\n",
        "    model_load(args.resume)\n",
        "    optimizer.param_groups[0]['lr'] = args.lr\n",
        "    model.dropouti, model.dropouth, model.dropout, args.dropoute = args.dropouti, args.dropouth, args.dropout, args.dropoute\n",
        "    if args.wdrop:\n",
        "        from weight_drop import WeightDrop\n",
        "        for rnn in model.rnns:\n",
        "            if type(rnn) == WeightDrop: rnn.dropout = args.wdrop\n",
        "            elif rnn.zoneout > 0: rnn.zoneout = args.wdrop\n",
        "###\n",
        "if not criterion:\n",
        "    splits = []\n",
        "    if ntokens > 500000:\n",
        "        # One Billion\n",
        "        # This produces fairly even matrix mults for the buckets:\n",
        "        # 0: 11723136, 1: 10854630, 2: 11270961, 3: 11219422\n",
        "        splits = [4200, 35000, 180000]\n",
        "    elif ntokens > 75000:\n",
        "        # WikiText-103\n",
        "        splits = [2800, 20000, 76000]\n",
        "    print('Using', splits)\n",
        "    criterion = SplitCrossEntropyLoss(args.emsize, splits=splits, verbose=False)\n",
        "###\n",
        "if args.cuda:\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "###\n",
        "params = list(model.parameters()) + list(criterion.parameters())\n",
        "total_params = sum(x.size()[0] * x.size()[1] if len(x.size()) > 1 else x.size()[0] for x in params if x.size())\n",
        "print('Args:', args)\n",
        "print('Model total parameters:', total_params)"
      ],
      "metadata": {
        "id": "P-lv_fRwXbch",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "042f5c73-a9d4-453a-ca64-f77ed31063de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LSTM(1500, 200), LSTM(200, 200), LSTM(200, 1500)]\n",
            "Using []\n",
            "Args: Namespace(data='data/ptb/', model='LSTM', emsize=1500, nhid=200, nlayers=3, lr=0.1, epochs=200, batch_size=20, bptt=70, dropout=0, dropouth=0, dropouti=0, dropoute=0, wdrop=0, seed=1111, nonmono=1111, cuda=True, log_interval=200, save='16845274093862257.pt', alpha=2, beta=1, wdecay=0.0005, resume='', when=[-1], optim='sgd', momentum=0.9, beta1=0.9, beta2=0.999, final_lr=0.1, gamma=0.001, ita=0.01, weight_decay=0.0005, tied=True)\n",
            "Model total parameters: 26905200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "###############################################################################\n",
        "# Training code\n",
        "###############################################################################\n",
        "\n",
        "def evaluate(data_source, batch_size=10):\n",
        "    # Turn on evaluation mode which disables dropout.\n",
        "    model.eval()\n",
        "    if args.model == 'QRNN': model.reset()\n",
        "    total_loss = 0\n",
        "    ntokens = len(corpus.dictionary)\n",
        "    hidden = model.init_hidden(batch_size)\n",
        "    for i in range(0, data_source.size(0) - 1, args.bptt):\n",
        "        data, targets = get_batch(data_source, i, args, evaluation=True)\n",
        "        output, hidden = model(data, hidden)\n",
        "        total_loss += len(data) * criterion(model.decoder.weight, model.decoder.bias, output, targets).data\n",
        "        hidden = repackage_hidden(hidden)\n",
        "    return total_loss.item() / len(data_source)\n",
        "\n",
        "\n",
        "def train():\n",
        "    # Turn on training mode which enables dropout.\n",
        "    if args.model == 'QRNN': model.reset()\n",
        "    total_loss = 0\n",
        "    # start_time = time.time()\n",
        "    ntokens = len(corpus.dictionary)\n",
        "    hidden = model.init_hidden(args.batch_size)\n",
        "    batch, i = 0, 0\n",
        "    while i < train_data.size(0) - 1 - 1:\n",
        "        bptt = args.bptt if np.random.random() < 0.95 else args.bptt / 2.\n",
        "        # Prevent excessively small or negative sequence lengths\n",
        "        seq_len = max(5, int(np.random.normal(bptt, 5)))\n",
        "        # There's a very small chance that it could select a very long sequence length resulting in OOM\n",
        "        # seq_len = min(seq_len, args.bptt + 10)\n",
        "\n",
        "        lr2 = optimizer.param_groups[0]['lr']\n",
        "        optimizer.param_groups[0]['lr'] = lr2 * seq_len / args.bptt\n",
        "        model.train()\n",
        "        data, targets = get_batch(train_data, i, args, seq_len=seq_len)\n",
        "\n",
        "        # Starting each batch, we detach the hidden state from how it was previously produced.\n",
        "        # If we didn't, the model would try backpropagating all the way to start of the dataset.\n",
        "        hidden = repackage_hidden(hidden)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output, hidden, rnn_hs, dropped_rnn_hs = model(data, hidden, return_h=True)\n",
        "        raw_loss = criterion(model.decoder.weight, model.decoder.bias, output, targets)\n",
        "\n",
        "        loss = raw_loss\n",
        "        # Activiation Regularization\n",
        "        if args.alpha: loss = loss + sum(args.alpha * dropped_rnn_h.pow(2).mean() for dropped_rnn_h in dropped_rnn_hs[-1:])\n",
        "        # Temporal Activation Regularization (slowness)\n",
        "        if args.beta: loss = loss + sum(args.beta * (rnn_h[1:] - rnn_h[:-1]).pow(2).mean() for rnn_h in rnn_hs[-1:])\n",
        "        loss.backward()\n",
        "\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        # if args.clip: torch.nn.utils.clip_grad_norm_(params, args.clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += raw_loss.data\n",
        "        optimizer.param_groups[0]['lr'] = lr2\n",
        "        # if batch % args.log_interval == 0 and batch > 0:\n",
        "        # total_loss = 0\n",
        "            # start_time = time.time()\n",
        "        ###\n",
        "        batch += 1\n",
        "        i += seq_len\n",
        "\n",
        "    train_loss = total_loss.item() / batch\n",
        "    # elapsed = time.time() - start_time\n",
        "    print('train_loss  {:5.2f} | train_ppl {:8.2f} | train_bpc {:8.3f}'.format(\n",
        "        train_loss, math.exp(train_loss), train_loss / math.log(2)))\n",
        "# Loop over epochs.\n",
        "lr = args.lr\n",
        "best_val_loss = []\n",
        "stored_loss = 100000000\n",
        "\n",
        "def create_optimizer(args, model_params):\n",
        "    if args.optim == 'sgd':\n",
        "        return optim.SGD(model_params, args.lr, momentum=args.momentum,\n",
        "                         weight_decay=args.weight_decay)\n",
        "    elif args.optim == 'adagrad':\n",
        "        return optim.Adagrad(model_params, args.lr, weight_decay=args.weight_decay)\n",
        "    elif args.optim == 'adam':\n",
        "        return optim.Adam(model_params, args.lr, betas=(args.beta1, args.beta2),\n",
        "                          weight_decay=args.weight_decay)\n",
        "    elif args.optim == 'amsgrad':\n",
        "        return optim.Adam(model_params, args.lr, betas=(args.beta1, args.beta2),\n",
        "                          weight_decay=args.weight_decay, amsgrad=True)\n",
        "    elif args.optim == 'adabound':\n",
        "        return AdaBound(model_params, args.lr, betas=(args.beta1, args.beta2),\n",
        "                        final_lr=args.final_lr, gamma=args.gamma,\n",
        "                        weight_decay=args.weight_decay)\n",
        "    else:\n",
        "        assert args.optim == 'amsbound'\n",
        "        return AdaBound(model_params, args.lr, betas=(args.beta1, args.beta2),\n",
        "                        final_lr=args.final_lr, gamma=args.gamma,\n",
        "                        weight_decay=args.weight_decay, amsbound=True)\n",
        "\n",
        "# At any point you can hit Ctrl + C to break out of training early.\n",
        "try:\n",
        "    optimizer = create_optimizer(args, model.parameters())\n",
        "    for epoch in range(1, args.epochs+1):\n",
        "        epoch_start_time = time.time()\n",
        "        print(\"epoch:\" + str(epoch))\n",
        "        train()\n",
        "        if 't0' in optimizer.param_groups[0]:\n",
        "            tmp = {}\n",
        "            for prm in model.parameters():\n",
        "                tmp[prm] = prm.data.clone()\n",
        "                prm.data = optimizer.state[prm]['ax'].clone()\n",
        "\n",
        "            test_loss = evaluate(test_data, test_batch_size)\n",
        "            print('test loss {:5.2f} | test ppl {:8.2f} | test bpc {:8.3f}'.format(\n",
        "                test_loss, math.exp(test_loss), test_loss / math.log(2)))\n",
        "            val_loss2 = evaluate(val_data)\n",
        "            print('-' * 89)\n",
        "            print(' valid loss {:5.2f} | '\n",
        "                'valid ppl {:8.2f} | valid bpc {:8.3f}'.format(\n",
        "                    val_loss2, math.exp(val_loss2), val_loss2 / math.log(2)))\n",
        "            print('-' * 89)\n",
        "\n",
        "            if val_loss2 < stored_loss:\n",
        "                model_save(args.save)\n",
        "                print('Saving Averaged!')\n",
        "                stored_loss = val_loss2\n",
        "\n",
        "            for prm in model.parameters():\n",
        "                prm.data = tmp[prm].clone()\n",
        "\n",
        "        else:\n",
        "            val_loss = evaluate(val_data, eval_batch_size)\n",
        "            print('-' * 89)\n",
        "            print(' valid loss {:5.2f} | '\n",
        "                'valid ppl {:8.2f} | valid bpc {:8.3f}'.format(\n",
        "              val_loss, math.exp(val_loss), val_loss / math.log(2)))\n",
        "            print('-' * 89)\n",
        "\n",
        "            if val_loss < stored_loss:\n",
        "                model_save(args.save)\n",
        "                print('Saving model (new best validation)')\n",
        "                stored_loss = val_loss\n",
        "\n",
        "            if args.optim == 'sgd' and 't0' not in optimizer.param_groups[0] and (len(best_val_loss)>args.nonmono and val_loss > min(best_val_loss[:-args.nonmono])):\n",
        "                print('Switching to ASGD')\n",
        "                optimizer = torch.optim.ASGD(model.parameters(), lr=args.lr, t0=0, lambd=0., weight_decay=args.wdecay)\n",
        "\n",
        "            if epoch in args.when:\n",
        "                print('Saving model before learning rate decreased')\n",
        "                model_save('{}.e{}'.format(args.save, epoch))\n",
        "                print('Dividing learning rate by 10')\n",
        "                optimizer.param_groups[0]['lr'] /= 10.\n",
        "\n",
        "            best_val_loss.append(val_loss)\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print('-' * 89)\n",
        "    print('Exiting from training early')\n",
        "\n",
        "# Load the best saved model.\n",
        "model_load(args.save)\n",
        "\n",
        "# Run on test data."
      ],
      "metadata": {
        "id": "3aVdQQiEXj_n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "a7c04815-516b-4f37-fa75-3710d7ef4afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1\n",
            "train_loss   5.28 | train_ppl   196.39 | train_bpc    7.618\n",
            "-----------------------------------------------------------------------------------------\n",
            " valid loss  5.33 | valid ppl   207.43 | valid bpc    7.696\n",
            "-----------------------------------------------------------------------------------------\n",
            "Saving model (new best validation)\n",
            "epoch:2\n",
            "train_loss   5.27 | train_ppl   194.86 | train_bpc    7.606\n",
            "-----------------------------------------------------------------------------------------\n",
            " valid loss  5.33 | valid ppl   206.69 | valid bpc    7.691\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "Exiting from training early\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-7542cfc5bada>\u001b[0m in \u001b[0;36m<cell line: 160>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;31m# Load the best saved model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m \u001b[0mmodel_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;31m# Run on test data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-be4d9378ef1c>\u001b[0m in \u001b[0;36mmodel_load\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             \u001b[0mtyped_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'data/{key}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_untyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m         \u001b[0;31m# TODO: Once we decide to break serialization FC, we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0;31m# stop wrapping with TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed locating file data/3: file not found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbmOIwkUeDO3",
        "outputId": "e1d121e6-7be7-4691-b403-c86dcbd683ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}